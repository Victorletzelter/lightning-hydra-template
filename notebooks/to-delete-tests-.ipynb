{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N, T, B = 2, 5, 16\n",
    "in_features, out_features = B//4, 10\n",
    "\n",
    "# create input tensor of shape [NxTxB/4]\n",
    "x = torch.randn(N, T, in_features)\n",
    "\n",
    "x = x.view(-1, x.shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19699/246092982.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubset_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_subsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mframe_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_frame_recall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdoa_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_doa_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19699/246092982.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubset_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_subsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mframe_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_frame_recall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdoa_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_doa_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "outputs = [{'test_frame_recall': torch.tensor(0.3688), 'test_doa_error': torch.tensor(float('nan'))}]\n",
    "num_subsets = len(outputs)\n",
    "\n",
    "for subset_idx in range(num_subsets):\n",
    "    frame_recall = torch.stack([x['test_frame_recall'] for x in outputs[subset_idx]])\n",
    "    doa_error = torch.stack([x['test_doa_error'] for x in outputs[subset_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3688])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x['test_frame_recall'] for x in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# apply linear layer to each time step\n",
    "x = torch.nn.Linear(in_features, out_features)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reshape output tensor to [N x T x S]\n",
    "x = x.view(*x.shape[:-1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PackedSequence' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43939/1109528434.py\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpacked_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mlinear_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# output tensor of shape [N x T x S]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_43939/1109528434.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# reshape input tensor to [N*T x B/4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# apply linear layer to each time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PackedSequence' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # reshape input tensor to [N*T x B/4]\n",
    "        x = x.view(-1, x.shape[-1])\n",
    "\n",
    "        # apply linear layer to each time step\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # reshape output tensor to [N x T x S]\n",
    "        x = x.view(*x.shape[:-1], -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Example usage\n",
    "N, T, B = 2, 5, 16\n",
    "in_features, out_features = B//4, 10\n",
    "\n",
    "# create input tensor of shape [NxTxB/4]\n",
    "x = torch.randn(N, T, in_features)\n",
    "\n",
    "# pack input tensor and apply time-distributed linear layer\n",
    "packed_x = rnn_utils.pack_padded_sequence(x, lengths=[T]*N, batch_first=True, enforce_sorted=False)\n",
    "linear_layer = TimeDistributed(in_features, out_features)\n",
    "y, _ = rnn_utils.pad_packed_sequence(linear_layer(packed_x)[0], batch_first=True)\n",
    "\n",
    "# output tensor of shape [N x T x S]\n",
    "print(y.shape)  # should be [2, 5, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class TimeDistributedFC(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for applying time distributed fully connected layers with input tensors \n",
    "    of shape  [N, T, in_features] where N is the batch_size, T is the number of time step,\n",
    "    and in_features is the number of input features at each time step. \n",
    "    Output tensors will have shape [N, T, out_features], where out_features is the number \n",
    "    of output features at each time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(TimeDistributedFC, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        N,T = x.shape[0],x.shape[1]\n",
    "        \n",
    "        # reshape input tensor to [N*T x B/4]\n",
    "        x = x.view(-1, x.shape[-1])\n",
    "\n",
    "        # # apply linear layer to each time step\n",
    "        # x = self.linear(x)\n",
    "\n",
    "        # reshape output tensor to [N x T x S]\n",
    "        x = x.view(N, T,-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "N, T, B = 2, 5, 16\n",
    "in_features, out_features = B//4, 10\n",
    "\n",
    "# create input tensor of shape [NxTxB/4]\n",
    "x = torch.randn(N, T, in_features)\n",
    "\n",
    "# # pack input tensor and apply time-distributed linear layer\n",
    "# packed_x = rnn_utils.pack_padded_sequence(x, lengths=[T]*N, batch_first=True, enforce_sorted=False)\n",
    "linear_layer = TimeDistributedFC(in_features, out_features)\n",
    "# y, _ = rnn_utils.pad_packed_sequence(linear_layer(packed_x)[0], batch_first=True)\n",
    "y = linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3244,  0.4101, -1.5298,  0.9352])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[i,j,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N = 2\n",
    "T = 20\n",
    "directions_of_arrival = []\n",
    "num_hypothesis = 10\n",
    "        \n",
    "for i in range(num_hypothesis) :\n",
    "    directions_of_arrival.append(torch.randn(size = (N,T,2))) # Size [NxTx2]\n",
    "    \n",
    "hyp_stacked = torch.stack(directions_of_arrival, dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "T = 20\n",
    "directions_of_arrival = []\n",
    "num_hypothesis = 10\n",
    "\n",
    "directions_of_arrival = torch.randn(size = (N,T,2*num_hypothesis)) # Size [NxTx(2*num_hypothesis)]\n",
    "hyps_splitted = torch.split(directions_of_arrival, [2 for i in range(num_hypothesis)], 2) #num_hypothesis-uples of elements of shape [N,T,2]\n",
    "hyps_stacked = torch.stack([h for h in hyps_splitted], dim=2) #Tuples of elements of shape [N,T,num_hypothesis,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 10, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyps_splitted)\n",
    "hyps_splitted[0].shape\n",
    "hyps_stacked.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "source_activity_target_t = torch.tensor([[1, 0, 1], [0, 1, 0]])\n",
    "direction_of_arrival_target_t = torch.tensor(\n",
    "    [[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11, 12]]]\n",
    ")\n",
    "\n",
    "direction_of_arrival_target_t[source_activity_target_t == 0, :] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   1,    2],\n",
       "         [1000, 1000],\n",
       "         [   5,    6]],\n",
       "\n",
       "        [[1000, 1000],\n",
       "         [   9,   10],\n",
       "         [1000, 1000]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direction_of_arrival_target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [{'test_frame_recall': torch.tensor(0.9925), 'test_doa_error': torch.tensor(16.2175)}, \n",
    " {'test_frame_recall': torch.tensor(0.9950), 'test_doa_error': torch.tensor(10.0907)}, \n",
    " {'test_frame_recall': torch.tensor(0.9950), 'test_doa_error': torch.tensor(14.7058)}, \n",
    " {'test_frame_recall': torch.tensor(0.9862), 'test_doa_error': torch.tensor(8.9629)}, \n",
    " {'test_frame_recall': torch.tensor(0.9613), 'test_doa_error': torch.tensor(16.7399)}, \n",
    " {'test_frame_recall': torch.tensor(0.9975), 'test_doa_error': torch.tensor(16.7870)}, \n",
    " {'test_frame_recall': torch.tensor(0.9775), 'test_doa_error': torch.tensor(10.8708)}, \n",
    " {'test_frame_recall': torch.tensor(0.9962), 'test_doa_error': torch.tensor(12.1684)}, \n",
    " {'test_frame_recall': torch.tensor(0.9912), 'test_doa_error': torch.tensor(14.0261)}, \n",
    " {'test_frame_recall': torch.tensor(0.9900), 'test_doa_error': torch.tensor(12.9945)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "            'model': [], 'dataset': [], 'fold_idx': [], 'subset_idx': [], 'frame_recall': [], 'doa_error': []\n",
    "        }\n",
    "frame_recall = torch.stack([x['test_frame_recall'] for x in outputs]).detach().cpu().numpy()\n",
    "doa_error = torch.stack([x['test_doa_error'] for x in outputs]).detach().cpu().numpy()\n",
    "\n",
    "num_sequences = len(frame_recall)\n",
    "\n",
    "for seq_idx in range(num_sequences):\n",
    "    results['model'].append('name')\n",
    "    results['dataset'].append('data')\n",
    "    results['fold_idx'].append(0)\n",
    "    results['subset_idx'].append(0)\n",
    "    results['frame_recall'].append(frame_recall[seq_idx])\n",
    "    results['doa_error'].append(doa_error[seq_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9925, 0.995, 0.995, 0.9862, 0.9613, 0.9975, 0.9775, 0.9962, 0.9912, 0.99]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['frame_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from importlib.util import find_spec\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List\n",
    "from pytorch_lightning import Callback\n",
    "from pytorch_lightning.loggers import Logger\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spherical_distance(y_pred: torch.Tensor,\n",
    "                                   y_true: torch.Tensor) -> torch.Tensor:\n",
    "        if (y_pred.shape[-1] != 2) or (y_true.shape[-1] != 2):\n",
    "            assert RuntimeError('Input tensors require a dimension of two.')\n",
    "\n",
    "        sine_term = torch.sin(y_pred[:, 0]) * torch.sin(y_true[:, 0])\n",
    "        cosine_term = torch.cos(y_pred[:, 0]) * torch.cos(y_true[:, 0]) * torch.cos(y_true[:, 1] - y_pred[:, 1])\n",
    "\n",
    "        return torch.acos(F.hardtanh(sine_term + cosine_term, min_val=-1, max_val=1))\n",
    "    \n",
    "batch = 2\n",
    "num_hyps = 10\n",
    "gts = torch.randn(batch,num_hyps,2)\n",
    "hyps_stacked_t=torch.randn(batch,num_hyps,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps_stacked_t_m = hyps_stacked_t.view(-1,2)\n",
    "gts_m = gts.view(-1,2)\n",
    "diff = compute_spherical_distance(hyps_stacked_t_m,gts_m)\n",
    "diff = diff.view(batch,num_hyps)\n",
    "spatial_epes = diff.unsqueeze(2).unsqueeze(3).unsqueeze(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "# hyps_stacked_t of shape (batch,num_hyps,2), gts of shape (batch, num_hyps, 2)\n",
    "# Compute the diff tensor using tensor operations\n",
    "sine_term = torch.sin(hyps_stacked_t[:, :, 0]) * torch.sin(gts[:, :, 0])  # (batch, num_hyps)\n",
    "cosine_term = torch.cos(hyps_stacked_t[:, :, 0]) * torch.cos(gts[:, :, 0]) * torch.cos(gts[:, :, 1] - hyps_stacked_t[:, :, 1])  # (batch, num_hyps)\n",
    "diff2 = torch.acos(torch.clamp(sine_term + cosine_term, min=-1, max=1))  # (batch, num_hyps)\n",
    "spatial_epes2 = diff2.unsqueeze(2).unsqueeze(3).unsqueeze(4)  # (batch, num_hyps, 1, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]],\n",
       "\n",
       "\n",
       "         [[[True]]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_epes == spatial_epes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
